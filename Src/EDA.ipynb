{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###\n",
    "### LIBRARIES\n",
    "###\n",
    "\n",
    "import load_data\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "\n",
    "# matplotlib\n",
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "from matplotlib import colors \n",
    "\n",
    "#seaborn\n",
    "import seaborn as sns\n",
    "\n",
    "# same as ggplot2 in R\n",
    "from plotnine import *\n",
    "\n",
    "# geographical plots\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point, Polygon\n",
    "import pysal.viz.mapclassify as mc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###\n",
    "### FUNCTIONS\n",
    "###\n",
    "\n",
    "def compute_daily_trend(df, variable):\n",
    "    \n",
    "    \"\"\"\n",
    "    This function computes daily increment, using the cumulative value as (value[i+1] - value[i])\n",
    "    \"\"\"\n",
    "     \n",
    "    n = df.shape[0]\n",
    "\n",
    "    aux = []\n",
    "\n",
    "    for i in range(n):\n",
    "        \n",
    "        if i==0:\n",
    "            aux.append(df[variable][i])\n",
    "        else:\n",
    "            region1 = df['denominazione_regione'][i-1]\n",
    "            region2 = df['denominazione_regione'][i]\n",
    "            if region1 != region2:\n",
    "                aux.append(df[variable][i])\n",
    "            else: \n",
    "                total1 = df[variable][i]\n",
    "                total2 = df[variable][i-1]\n",
    "                aux.append(total1 - total2)\n",
    "\n",
    "    return aux\n",
    "\n",
    "def plot_by_region(df, region):\n",
    "    \n",
    "    \"\"\"\n",
    "    This function shows two plots:\n",
    "        - time series of total cases, total recovered and total deaths for the specific region in input\n",
    "        - time series of daily increment of new cases, new recovered and new deaths for the specific region in input\n",
    "    \"\"\"\n",
    "    \n",
    "    total_cases = df[df['denominazione_regione'] == region]['totale_casi']\n",
    "    total_recovered = df[df['denominazione_regione'] == region]['dimessi_guariti']\n",
    "    total_deaths = df[df['denominazione_regione'] == region]['deceduti']\n",
    "    \n",
    "    increment_cases = df[df['denominazione_regione'] == region]['nuovi_positivi']\n",
    "    increment_recovered = df[df['denominazione_regione'] == region]['nuovi_dimessi']\n",
    "    increment_deaths = df[df['denominazione_regione'] == region]['nuovi_deceduti']\n",
    "    \n",
    "    # format date axis\n",
    "    dates = df[df['denominazione_regione'] == region]['date']\n",
    "    dates = [dt.datetime.strptime(d,'%Y-%m-%d').date() for d in dates]\n",
    "    \n",
    "    fig, ax = plt.subplots(nrows=2,ncols=1, sharex=True,figsize=(12, 10))\n",
    "    \n",
    "    # gives an interval locator in days\n",
    "    ax[0].xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m-%d'))\n",
    "    ax[0].xaxis.set_major_locator(mdates.DayLocator(interval=5))\n",
    "    \n",
    "    ax[0].plot(dates,total_cases,'-o', label = 'Total Cases')\n",
    "    ax[0].plot(dates,total_deaths,'-o', label = 'Total Deaths')\n",
    "    ax[0].plot(dates,total_recovered,'-o', label = 'Total Recoveredd')\n",
    "    \n",
    "    # position legend\n",
    "    ax[0].legend(loc='upper left')\n",
    "    \n",
    "    # gives an interval locator in days\n",
    "    ax[1].xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m-%d'))\n",
    "    ax[1].xaxis.set_major_locator(mdates.DayLocator(interval=5))\n",
    "    \n",
    "    ax[1].plot(dates,increment_cases,'-o', label = 'Increment Cases')\n",
    "    ax[1].plot(dates,increment_deaths,'-o', label = 'Increment Deaths')\n",
    "    ax[1].plot(dates,increment_recovered,'-o', label = 'Increment Recoveredd')\n",
    "    ax[1].legend(loc='upper left')\n",
    "    \n",
    "    fig.autofmt_xdate()\n",
    "    fig.suptitle('{}'.format(region))\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def pie_chart(df, region):\n",
    "    \n",
    "    \"\"\"\n",
    "    This function plots a pie chart of subdivision of positive cases in a specific region\n",
    "    \"\"\"\n",
    "    \n",
    "    # Data to plot\n",
    "    labels = ['recoverev with symptoms','intensive care','home isolation']\n",
    "    sizes = df[df['denominazione_regione']==region][labels]\n",
    "    colors = ['gold', 'yellowgreen', 'lightcoral']\n",
    "    explode = (0, 0, 0)  # explode 1st slice\n",
    "\n",
    "    # Plot\n",
    "    p, tx, autotexts = plt.pie(sizes, explode=explode, labels=labels, colors=colors, autopct=\"\", shadow=True,\n",
    "                               startangle=140)\n",
    "    for i, a in enumerate(autotexts):\n",
    "        perc = round((sizes.iloc[0,i]/np.array(sizes.sum(axis=1))[0]),3)*100\n",
    "        a.set_text(\"{} ({}%)\".format(sizes.iloc[0,i], perc))\n",
    "    \n",
    "    plt.title('Subdivision in {}'.format(region))\n",
    "    plt.axis('equal')\n",
    "    plt.show()\n",
    "    \n",
    "def geodata_plot_regions(italy, geo_df, variable):\n",
    "    \n",
    "    \"\"\"\n",
    "    This function shows a geographic plot of a specific variable distribution (total cases and so on) by region:\n",
    "    - italy: geodataframe of italy regions \n",
    "    - geo_df: geodataframe of Covid-19 data\n",
    "    \"\"\"\n",
    "    \n",
    "    geo_df_aggregated = geo_df.groupby('id_regione')[variable].sum().reset_index()\n",
    "    italy_merged = pd.merge(italy, geo_df_aggregated, how='inner', left_on='ID_1', right_on='id_regione')\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(12, 10))\n",
    "    italy_merged.plot(column=variable, legend = True, ax=ax)\n",
    "\n",
    "    plt.title('{}'.format(variable))\n",
    "    \n",
    "    \n",
    "def geodata_plot_provinces(italy, geo_df, region, variable, k=5):\n",
    "    \n",
    "    \"\"\"\n",
    "    This function shows a geographic plot of a specific region and its provinces.\n",
    "    - italy: geodataframe of italy provinces \n",
    "    - geo_df: geodataframe of Covid-19 data\n",
    "    \"\"\"\n",
    "    \n",
    "    if region == 'All':\n",
    "        geo_df = geo_df[['id_provincia',variable]]\n",
    "        italy_merged = pd.merge(italy, geo_df, how='left', left_on='ID_2', right_on='id_provincia')\n",
    "    else: \n",
    "        geo_df = geo_df[['id_provincia',variable]]\n",
    "        italy = italy[italy['NAME_1']==region]\n",
    "        italy_merged = pd.merge(italy, geo_df, how='left', left_on='ID_2', right_on='id_provincia')\n",
    "    \n",
    "    if italy_merged[variable].isna().any():\n",
    "        nan_exists = True\n",
    "    else:\n",
    "        nan_exists = False\n",
    "\n",
    "    \n",
    "    # defining quantiles based to k as input\n",
    "    quantiles = mc.Quantiles(italy_merged.totale_casi.dropna(), k=k)\n",
    "    variable_cat = variable + '_cat'\n",
    "    italy_merged[variable_cat] = quantiles.find_bin(italy_merged.totale_casi).astype('str')\n",
    "    italy_merged.loc[italy_merged.totale_casi.isnull(), variable_cat] = 'No Data'\n",
    "\n",
    "    cmap = plt.cm.get_cmap('Blues', k)\n",
    "    cmap_list = [colors.rgb2hex(cmap(i)) for i in range(cmap.N)]\n",
    "    cmap_final = colors.ListedColormap(cmap_list)\n",
    "\n",
    "    if nan_exists:\n",
    "        cmap_list.append('grey')\n",
    "        cmap_final = colors.ListedColormap(cmap_list)\n",
    "\n",
    "    # plot map\n",
    "    fig, ax = plt.subplots(figsize=(12, 10))\n",
    "    italy_merged.plot(column=variable_cat, edgecolor='k', cmap=cmap_final,\n",
    "             legend=True, legend_kwds=dict(loc='upper left'),\n",
    "             ax=ax)\n",
    "\n",
    "    # get all upper bounds in the quantiles category\n",
    "    upper_bounds = quantiles.bins\n",
    "    # get and format all bounds\n",
    "    bounds = []\n",
    "    for index, upper_bound in enumerate(upper_bounds):\n",
    "        if index == 0:\n",
    "            lower_bound = italy_merged.totale_casi.min()\n",
    "        else:\n",
    "            lower_bound = upper_bounds[index-1]\n",
    "\n",
    "        bound = f'{lower_bound:.2f} - {upper_bound:.2f}'\n",
    "        bounds.append(bound)\n",
    "\n",
    "    # get all the legend labels\n",
    "    leg = ax.get_legend()\n",
    "    legend_labels = leg.get_texts()\n",
    "    # replace the numerical legend labels\n",
    "    for bound, legend_label in zip(bounds, legend_labels):\n",
    "        legend_label.set_text(bound)\n",
    "    \n",
    "    # position legend outside\n",
    "    leg.set_bbox_to_anchor((1.05, 1.0))\n",
    "    # call it to not cut the legend and to fit correctly the plot\n",
    "    plt.tight_layout()\n",
    "    plt.title('{}: {}'.format(region,variable))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###\n",
    "### DIRECTORIES\n",
    "###\n",
    "\n",
    "PROJECT_DIR = os.getcwd()\n",
    "DATA_DIR = os.path.join(os.path.dirname(PROJECT_DIR),'Data')\n",
    "SHAPEFILES_DIR = os.path.join(os.path.dirname(PROJECT_DIR),'Shapefiles')\n",
    "# RESULTS_DIR = os.path.join(os.path.dirname(PROJECT_DIR),'Results')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###\n",
    "### LOADING DATA\n",
    "###\n",
    "\n",
    "### 1) Covid_Data: if anything is specified, loads data using url github to repository.\n",
    "###                if a DATA_DIR is specified, loads data downloaded as csv\n",
    "data_provinces, data_regions, data_national = load_data.load_covid_data()\n",
    "\n",
    "### 2) Shapefiles: if anything is specified, loads data using url github to repository.\n",
    "###                if a DATA_DIR is specified, loads data downloaded as csv\n",
    "italy_provinces, italy_regions = load_data.load_shapefiles(SHAPEFILES_DIR)\n",
    "\n",
    "# data wrangling\n",
    "data_regions = data_regions.sort_values(['denominazione_regione','data'])\n",
    "data_regions = data_regions.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###\n",
    "### FEATURE ENGINEERING\n",
    "### \n",
    "\n",
    "# 2) REGIONE\n",
    "# Colonne:\n",
    "# 1. data: timestamp\n",
    "# 2. stato: sigla stato italiano\n",
    "# 3. codice_regione: numero codice regione\n",
    "# 4. denominazione_regione: nome della regione\n",
    "# 5-6. lat e long: coordinate\n",
    "# 7. ricoverati_con_sintomi: totale del numero di ricoverati \n",
    "# 8. terapia_intensiva: totale del numero di pazienti in terapia intensiva\n",
    "# 9. totale_ospedalizzati: somma di 7 + 8\n",
    "# 10. isolamento_domiciliare: totale del numero di isolati\n",
    "# 11. totale_attualmente_positivi: totale del numero di contagiati \n",
    "# 12. nuovi_attualmente_positivi: numero di nuovi positivi in quel giorno\n",
    "# 13. dimessi_guariti: totale dei dimessi guariti \n",
    "# 14. deceduti: totale dei deceduti\n",
    "# 15. totale_casi: totale di 11 + 13 + 14\n",
    "# 15. tamponi: totale dei tamponi\n",
    "\n",
    "\n",
    "# 1) Calcolo variabili giornaliere: (i+1 - i)\n",
    "new_dimessi = compute_daily_trend(data_regions, 'dimessi_guariti')\n",
    "new_deceduti = compute_daily_trend(data_regions, 'deceduti')\n",
    "new_tamponi = compute_daily_trend(data_regions, 'tamponi')\n",
    "\n",
    "data_regions['nuovi_dimessi'] = new_dimessi\n",
    "data_regions['nuovi_deceduti'] = new_deceduti\n",
    "data_regions['nuovi_tamponi'] = new_tamponi\n",
    "\n",
    "# 2) calcolo anno, mese e giorno da campo data:\n",
    "data_regions['date'] = data_regions['data'].apply(lambda x: x[:10])\n",
    "data_regions['Anno'] = data_regions['date'].apply(lambda x: dt.datetime.strptime(x, \"%Y-%m-%d\").year)\n",
    "data_regions['Mese'] = data_regions['date'].apply(lambda x: dt.datetime.strptime(x, \"%Y-%m-%d\").month)\n",
    "data_regions['Giorno'] = data_regions['date'].apply(lambda x: dt.datetime.strptime(x, \"%Y-%m-%d\").day)\n",
    "#dati_regioni = dati_regioni.drop(columns='date')\n",
    "\n",
    "\n",
    "# Salvare nuovo csv\n",
    "# data_regions.to_csv(os.path.join(RESULTS_DIR,'regions.csv'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###\n",
    "### EXPLORATORY DATA ANALYSIS - TOTAL VIEW\n",
    "### \n",
    "\n",
    "# totale regioni\n",
    "\n",
    "totale_regioni = data_regions.groupby('denominazione_regione')['totale_casi'].max().to_frame('totale_casi').reset_index()\n",
    "totale_regioni = totale_regioni.sort_values('totale_casi', ascending = False)\n",
    "\n",
    "\n",
    "### bar charts totale casi\n",
    "\n",
    "# 1) ggplot\n",
    "(ggplot(totale_regioni)) +\\\n",
    "   geom_col(aes(x='denominazione_regione',y='totale_casi')) + theme(axis_text=element_text(angle = 90, hjust = 1))\n",
    "\n",
    "# 2) seaborn\n",
    "plt.figure(figsize=(6,6))\n",
    "ax = sns.barplot(x=\"denominazione_regione\", y=\"totale_casi\", data=totale_regioni)#, palette=sns.color_palette(\"GnBu\", 10))\n",
    "plt.xticks(rotation='vertical')\n",
    "plt.show()\n",
    "\n",
    "### evoluzione totale casi per regione\n",
    "(ggplot(data_regions) +\\\n",
    "   geom_point(aes(x='date',y='totale_casi', color = 'factor(denominazione_regione)')) +\\\n",
    "theme(axis_text=element_text(angle = 90, hjust = 1)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###\n",
    "### EXPLORATORY DATA ANALYSIS - BY REGION\n",
    "### \n",
    "\n",
    "# totals & increments\n",
    "plot_by_region(data_regions, 'Lombardia')\n",
    "\n",
    "# pie chart\n",
    "# totale_regioni_2 = data_regions.groupby('denominazione_regione')\\\n",
    "# [['ricoverati_con_sintomi','terapia_intensiva','isolamento_domiciliare']].max().reset_index()\n",
    "# pie_chart(totale_regioni_2,'Marche')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###\n",
    "### EXPLORATORY DATA ANALYSIS - Geographic Plots\n",
    "### \n",
    "\n",
    "### dictionaries\n",
    "_, dictionary_regions, dictionary_provinces = load_data.dictionary_creation()\n",
    "\n",
    "### 1) REGIONS\n",
    "# We need to build a geodataframe for Covid-19 data: it needs a shapely object \n",
    "# from the lat and long of the regions in our dataset...\n",
    "# ATT: We should always verify the crs (coordinate reference system)\n",
    "df_aggregated_regions = data_regions.groupby('denominazione_regione')\\\n",
    "[['lat','long','totale_casi','deceduti','dimessi_guariti']].max().reset_index()\n",
    "geometry_regions = [Point(xy) for xy in zip(df_aggregated_regions['long'],df_aggregated_regions['lat'])]\n",
    "\n",
    "# ...we feed now the geodataframe\n",
    "geo_df_regions = gpd.GeoDataFrame(df_aggregated_regions,  geometry = geometry_regions)\n",
    "\n",
    "# dictionaries of regions id in order to map with shape file of italy regions\n",
    "geo_df_regions['id_regione'] = geo_df_regions['denominazione_regione'].map(dictionary_regions)\n",
    "\n",
    "\n",
    "\n",
    "### 2) PROVINCES\n",
    "\n",
    "# We need to build a geodataframe for Covid-19 data: it needs a shapely object \n",
    "# from the lat and long of the regions in our dataset...\n",
    "# ATT: We should always verify the crs (coordinate reference system)\n",
    "df_aggregated_provinces = data_provinces.groupby(['denominazione_regione','denominazione_provincia'])[['totale_casi','lat','long']]\\\n",
    ".max().reset_index()\n",
    "geometry_provinces = [Point(xy) for xy in zip(df_aggregated_provinces['long'],df_aggregated_provinces['lat'])]\n",
    "\n",
    "# ...we feed now the geodataframe\n",
    "geo_df_provinces = gpd.GeoDataFrame(df_aggregated_provinces,  geometry = geometry_provinces)\n",
    "\n",
    "# dictionaries of provinces id in order to map with shape file of italy provinces\n",
    "geo_df_provinces['id_provincia'] = geo_df_provinces['denominazione_provincia'].map(dictionary_provinces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###\n",
    "### EXPLORATORY DATA ANALYSIS - Geographic Plots\n",
    "### \n",
    "\n",
    "# geographic plot of all regions\n",
    "geodata_plot_regions(italy_regions, geo_df_regions, 'totale_casi')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###\n",
    "### EXPLORATORY DATA ANALYSIS - Geographic Plots\n",
    "### \n",
    "\n",
    "# geogrpahic plot of specific region with its provinces\n",
    "geodata_plot_provinces(italy_provinces,geo_df_provinces,'Lombardia','totale_casi', k= 10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GEOPANDAS",
   "language": "python",
   "name": "geopandas"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
