{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Bad key \"text.kerning_factor\" on line 4 in\n",
      "C:\\Users\\rivo9\\Anaconda3\\envs\\GEOPANDAS\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test_patch.mplstyle.\n",
      "You probably need to get an updated matplotlibrc file from\n",
      "https://github.com/matplotlib/matplotlib/blob/v3.1.3/matplotlibrc.template\n",
      "or from the matplotlib source distribution\n",
      "C:\\Users\\rivo9\\Anaconda3\\envs\\GEOPANDAS\\lib\\site-packages\\pysal\\model\\spvcm\\abstracts.py:10: UserWarning: The `dill` module is required to use the sqlite backend fully.\n",
      "  from .sqlite import head_to_sql, start_sql\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "###\n",
    "### LIBRARIES\n",
    "###\n",
    "\n",
    "# sctipt for data loding\n",
    "import load_data\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random as rn\n",
    "import datetime as dt\n",
    "\n",
    "# matplotlib\n",
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "from matplotlib import colors \n",
    "\n",
    "#seaborn\n",
    "import seaborn as sns\n",
    "\n",
    "# same as ggplot2 in R\n",
    "from plotnine import *\n",
    "\n",
    "# geographical plots\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point, Polygon\n",
    "import pysal.viz.mapclassify as mc\n",
    "\n",
    "\n",
    "from scipy.optimize import curve_fit, fsolve\n",
    "import tensorflow as tf\n",
    "\n",
    "#########################################################################################\n",
    "#In order to keep the results of deep learning models as much \n",
    "# reproducibles as possible\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\"\n",
    "\n",
    "# The below is necessary for starting Numpy generated random numbers\n",
    "# in a well-defined initial state.\n",
    "np.random.seed(42)\n",
    "\n",
    "# The below is necessary for starting core Python generated random numbers\n",
    "# in a well-defined state.\n",
    "rn.seed(12345)\n",
    "\n",
    "# Force TensorFlow to use single thread.\n",
    "# Multiple threads are a potential source of non-reproducible results.\n",
    "session_conf = tf.compat.v1.ConfigProto(intra_op_parallelism_threads=1,\n",
    "                              inter_op_parallelism_threads=1)\n",
    "\n",
    "# The below tf.random.set_seed() will make random number generation\n",
    "# in the TensorFlow backend have a well-defined initial state.\n",
    "# For further details, see:\n",
    "tf.random.set_seed(1234)\n",
    "\n",
    "sess = tf.compat.v1.Session(graph=tf.compat.v1.get_default_graph(), config=session_conf)\n",
    "tf.compat.v1.keras.backend.set_session(sess)\n",
    "##########################################################################################\n",
    "\n",
    "\n",
    "# Deep learning library for LSTM\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Bidirectional\n",
    "from keras.layers import Dropout\n",
    "from keras.optimizers import Adam\n",
    "from keras import initializers\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "import itertools\n",
    "from copy import deepcopy\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "###\n",
    "### FUNCTIONS\n",
    "###\n",
    "\n",
    "def logistic_model(x,a,b,c):\n",
    "    \n",
    "    return c/(1+np.exp(-(x-b)/a))\n",
    "\n",
    "def fit_log_model(data, region):\n",
    "    \n",
    "    aux = data_regions[data_regions['denominazione_regione']==region]\n",
    "    x = aux['timestamp']\n",
    "    y = aux['totale_casi']\n",
    "    \n",
    "    fit = curve_fit(logistic_model,x,y,p0=[2,100,20000])\n",
    "    \n",
    "    return fit\n",
    "\n",
    "def plot_forecasting_logistic(df_regions, df_forecasting, region, FMT, start_date):\n",
    "    \n",
    "    df_regions_subset = df_regions[df_regions['denominazione_regione']==region][['timestamp','totale_casi']]\n",
    "    \n",
    "    df_forecasting_subset = df_forecasting[df_forecasting['Region']==region]\n",
    "    \n",
    "    a = df_forecasting_subset['a'].values\n",
    "    b = df_forecasting_subset['b'].values\n",
    "    c = df_forecasting_subset['c'].values\n",
    "    end_date = df_forecasting_subset['End_Date'].values\n",
    "    \n",
    "    # max time \n",
    "    max_time = np.max(df_regions_subset['timestamp'])\n",
    "    end_time = (dt.datetime.strptime(end_date[0],FMT) - dt.datetime.strptime(start_date, FMT)).days\n",
    "    \n",
    "    # plot\n",
    "    x_forecast = range(max_time + 1, end_time)\n",
    "    forecast = logistic_model(x_forecast,a,b,c)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(10, 8))\n",
    "    plt.scatter(df_regions_subset['timestamp'],df_regions_subset['totale_casi'])\n",
    "    plt.scatter(range(max_time + 1, end_time), logistic_model(range(max_time + 1, end_time),a,b,c))\n",
    "    plt.title('Forecasting: {}, End Date Estimated: {}'.format(region,end_date))\n",
    "    plt.show()\n",
    "\n",
    "def train_test_creation(timeseries, train_test_split = 0.2):\n",
    "    \n",
    "    n = len(timeseries)\n",
    "    train_len = int(n*(1-train_test_split))\n",
    "    train, test = timeseries[0:train_len], timeseries[train_len:]\n",
    "    \n",
    "    return train, test\n",
    "\n",
    "def scale(train, test = None):\n",
    "    \n",
    "    \"\"\"\n",
    "    Defines scale transform for data in input\n",
    "    \"\"\" \n",
    "    \n",
    "    if test.any():\n",
    "        # fit scaler\n",
    "        scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "        train = train.reshape(-1, 1)\n",
    "        test = test.reshape(-1, 1)\n",
    "        scaler = scaler.fit(train)\n",
    "        # transform train\n",
    "        train_scaled = scaler.transform(train)\n",
    "        # # transform test\n",
    "        test_scaled = scaler.transform(test)\n",
    "        return scaler, train_scaled, test_scaled\n",
    "    else:\n",
    "        # fit scaler\n",
    "        scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "        train = train.reshape(-1, 1)\n",
    "        scaler = scaler.fit(train)\n",
    "        # transform train\n",
    "        train_scaled = scaler.transform(train)\n",
    "        return scaler, train\n",
    "    \n",
    "\n",
    "def invert_scale(scaler, value):\n",
    "    \n",
    "    \"\"\"\n",
    "    Returns inverse scale transform for value in input\n",
    "    \"\"\"     \n",
    "\n",
    "    array = np.array(value)\n",
    "    array = array.reshape(-1, 1)\n",
    "    inverted = scaler.inverse_transform(array)\n",
    "    return inverted\n",
    "    \n",
    "def create_data(data, time_steps):\n",
    "    \n",
    "    \"\"\"\n",
    "    Transform time series sequence to supervised sequence for LSTM\n",
    "    \"\"\" \n",
    "    \n",
    "    n = len(data)\n",
    "    X, y = list(), list()\n",
    "    \n",
    "    for i in range(n - time_steps):\n",
    "        aux_x = data[i:(i+time_steps)]\n",
    "        aux_y = data[i+time_steps]\n",
    "        \n",
    "        X.append(aux_x)\n",
    "        y.append(aux_y)\n",
    "    \n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "def forecast_univariate_lstm(model, X):\n",
    "    X = X.reshape(1, len(X),1 )\n",
    "    yhat = model.predict(X)\n",
    "    return yhat[0,0]\n",
    "\n",
    "def forecast_point_by_point_univariate_lstm(data, n_steps, forecast_window):\n",
    "    \n",
    "    \"\"\"\n",
    "    Given a specific forecast window (int), this functions computes predictions point-by-point.\n",
    "    \"\"\" \n",
    "    \n",
    "    predictions_new = list()\n",
    "    start_sequence = data[-n_steps:]\n",
    "    \n",
    "    for i in range(forecast_window):\n",
    "        aux = forecast_univariate_lstm(prova.model, start_sequence)\n",
    "        start_sequence = np.insert(start_sequence, n_steps, aux)\n",
    "        start_sequence = start_sequence[-n_steps:]\n",
    "        predictions_new.append(aux)\n",
    "        \n",
    "    return predictions_new\n",
    "\n",
    "def plot_forecasting_LSTM(df, region, variable, predictions):\n",
    "    \n",
    "    print(region)\n",
    "    aux = df[df['denominazione_regione']==region][variable]\n",
    "    date = df[df['denominazione_regione']==region]['data']\n",
    "    date = date.apply(lambda x: x[0:10])\n",
    "    FMT = '%Y-%m-%d'\n",
    "    start_date_acquistion = dt.datetime.strptime(date.min(),FMT)\n",
    "    forecast_window = len(predictions)\n",
    "    end_date = dt.datetime.strptime(date.max(),FMT) + dt.timedelta(days=forecast_window + 1)\n",
    "\n",
    "    delta = end_date - start_date_acquistion       # as timedelta\n",
    "    times = list()\n",
    "    for i in range(delta.days + 1):\n",
    "        day = start_date_acquistion + dt.timedelta(days=i)\n",
    "        times.append(day)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize = (8,6))\n",
    "    ax.xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m-%d'))\n",
    "    ax.xaxis.set_major_locator(mdates.DayLocator(interval=5))\n",
    "\n",
    "    ax.plot(times[0:len(aux)], aux, '-ko', label='True', color = 'red')\n",
    "    ax.plot(times[len(aux):(len(aux) + len(predictions))], predictions, '-ko', label='Predicted', color = 'blue')\n",
    "    # position legend\n",
    "    ax.set_xlabel('Date')\n",
    "    ax.set_ylabel(variable)\n",
    "\n",
    "    ax.legend(loc='upper left')\n",
    "    \n",
    "    fig.autofmt_xdate()\n",
    "    fig.suptitle('{}'.format(region))\n",
    "    plt.show()\n",
    "\n",
    "def get_default_configuration(structure = 'classic',\n",
    "                               n_steps = 1,\n",
    "                               n_features = 1,\n",
    "                               neurons = 1,\n",
    "                               activation = 'linear',\n",
    "                               loss = 'mse',\n",
    "                               optimizer = 'adam',\n",
    "                               metrics = 'RMSE',\n",
    "                               epochs = 2,\n",
    "                               batch_size = 1):\n",
    "    \n",
    "    \"\"\"\n",
    "    Defines default network configuration for LSTM\n",
    "    \"\"\" \n",
    "\n",
    "    defaults = {'structure': structure, \n",
    "              'n_steps': n_steps, \n",
    "              'n_features': n_features,\n",
    "              'neurons': neurons,\n",
    "              'activation': activation, \n",
    "              'loss': loss, \n",
    "              'optimizer': optimizer, \n",
    "              'metrics': metrics, \n",
    "              'epochs': epochs, \n",
    "              'batch_size': batch_size}\n",
    "  \n",
    "    return defaults\n",
    "\n",
    "def get_tuning_model(options):\n",
    "    \n",
    "    \"\"\"\n",
    "    Returns a dict with all possible configuration given by options in input.\n",
    "    \"\"\"     \n",
    "\n",
    "    keys = options.keys()\n",
    "    values = (options[key] for key in keys)\n",
    "    tuning_model = [dict(zip(keys, combination)) for combination in itertools.product(*values)]\n",
    "\n",
    "    return tuning_model\n",
    "\n",
    "\n",
    "def run(train, test, param_dict, tuning_options = None, tuning_model = None):\n",
    "    \n",
    "    \"\"\"\n",
    "    This functions takes in input train and test data, along with the default configuration for the newtork and two other\n",
    "    possible dictionaries: tuning model and tuning options. \n",
    "    Tuning options is a dictionary with different values to tune for the parameters.\n",
    "    It works in the following way:\n",
    "        - build the network with default configuration.\n",
    "        - for each specific parameter in tuning options, vary it using the values in input while fixing all the others.\n",
    "        - run the model and save the metric.\n",
    "    Tuning model is a dictionary with alla possible configurations.\n",
    "    It works in the following way:\n",
    "        - Take the default configuration and substitute the configuration in input from the dictionary.\n",
    "        - run the model and save the metric.\n",
    "    \"\"\"\n",
    "\n",
    "    if tuning_model and tuning_options:\n",
    "        raise ValueError('You should specify only one between tuning parameters or tuning model...')\n",
    "        \n",
    "    \n",
    "    if tuning_options:\n",
    "        results = {}\n",
    "    \n",
    "        for parameter, options in  tuning_options.items():\n",
    "            results[parameter] = {}\n",
    "            param_dict_temp = deepcopy(param_dict)\n",
    "\n",
    "            for option in options:\n",
    "                print(\"\\nEvaluating parameter \\\"{}\\\" using value \\\"{}\\\"...\".format(parameter, option))\n",
    "                # Update the corresponding parameter\n",
    "                param_dict_temp[parameter] = option\n",
    "\n",
    "                try:\n",
    "                    n_steps = param_dict_temp['n_steps']\n",
    "                    # normalization to [-1,1]\n",
    "                    scaler, train_scaled, test_scaled = scale(train, test)\n",
    "                    X_train, y_train = create_data(train_scaled, n_steps)\n",
    "                    X_test, y_test = create_data(test_scaled, n_steps)\n",
    "                    # ... and then reshape into correct dimension for the network [samples, time_steps, n_features]\n",
    "                    X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1],1))\n",
    "                    X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1],1))\n",
    "                    \n",
    "                    print(\"param_dict_temp: {}\".format(param_dict_temp))\n",
    "                    results[parameter][option] = evaluation(X_train, y_train, X_test, y_test, param_dict_temp)\n",
    "                    \n",
    "                except Exception as e: \n",
    "                    results[parameter][option] = 'NaN'\n",
    "                    print('Error: {}, skipping...'.format(e))\n",
    "                    pass\n",
    "\n",
    "        return results\n",
    "    \n",
    "    # qui si salva accuratezza di configurazioni scelte a priori\n",
    "    elif tuning_model:\n",
    "        \n",
    "        # Itero sul numero di configurazioni da testare\n",
    "        for i in range(len(tuning_model)):\n",
    "            param_dict_temp = deepcopy(param_dict)\n",
    "            dict_aux = deepcopy(tuning_model[i])\n",
    "            \n",
    "            # modifico i parametri della configurazione di default\n",
    "            for parameter, options in dict_aux.items():\n",
    "                param_dict_temp[parameter] = options\n",
    "            \n",
    "            # valuto modello e salvo metrica di accuratezza\n",
    "            n_steps = param_dict_temp['n_steps']\n",
    "            # normalization to [-1,1]\n",
    "            scaler, train_scaled, test_scaled = scale(train, test)\n",
    "            X_train, y_train = create_data(train_scaled, n_steps)\n",
    "            X_test, y_test = create_data(test_scaled, n_steps)\n",
    "            # ... and then reshape into correct dimension for the network [samples, time_steps, n_features]\n",
    "            X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1],1))\n",
    "            X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1],1))\n",
    "            \n",
    "            tuning_model[i]['metric'] = evaluation(X_train, y_train, X_test, y_test, param_dict_temp)\n",
    "        \n",
    "        return pd.DataFrame(tuning_model)\n",
    "    \n",
    "def evaluation(X_train, y_train, X_test, y_test, param_dict):\n",
    "    \n",
    "    \"\"\"\n",
    "    Builds a LSTM model using the given params\n",
    "    \"\"\"\n",
    "    \n",
    "    aux = univariate_LSTM(structure = param_dict['structure'],\n",
    "                        n_steps = param_dict['n_steps'], \n",
    "                        n_features = param_dict['n_features'],\n",
    "                        neurons = param_dict['neurons'], \n",
    "                        activation = param_dict['activation'],\n",
    "                        loss = param_dict['loss'],\n",
    "                        optimizer = param_dict['optimizer'],\n",
    "                        metrics = param_dict['metrics'],\n",
    "                        epochs = param_dict['epochs'],\n",
    "                        batch_size = param_dict['batch_size'])\n",
    "    \n",
    "    aux.model_compile()\n",
    "    metric, history = aux.evaluate_model(X_train, y_train, X_test, y_test)\n",
    "    \n",
    "    ### save txt of the results\n",
    "    \n",
    "    return metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "###\n",
    "### CLASSES\n",
    "###\n",
    "\n",
    "class univariate_LSTM():\n",
    "    \n",
    "    \"\"\"\n",
    "    INTRODUCTION: This class implements different variation of LSTM architecture to model univariate time series\n",
    "    in input.\n",
    "    \n",
    "    PARAMETERS:\n",
    "        structure: string, which LSTM structure to use\n",
    "        n_steps: number of time steps used\n",
    "        n_features: number of features in input (1 if just univariate time series)\n",
    "        hidden_layers: int, number of hidden layers (excluding the input layer) ---> TO ADD\n",
    "        neurons: array of units/nodes in each layer\n",
    "        activation: str, activation function in all layers except output\n",
    "        loss: str, loss function\n",
    "        optimizer: str, optimizer\n",
    "        metrics: list of strings, metrics used\n",
    "        epochs: int, number of epochs to train for\n",
    "        batch_size: int, number of samples per batch\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, structure, n_steps, n_features, neurons, \n",
    "                 activation, loss,\n",
    "                 optimizer, metrics, epochs, batch_size):\n",
    "        \n",
    "        self.structure = structure\n",
    "        self.n_steps = n_steps\n",
    "        self.n_features = n_features\n",
    "        # self.num_layers = num_layers\n",
    "        self.neurons = neurons\n",
    "        self.activation = activation\n",
    "        # self.activation_out = activation_out\n",
    "        self.loss = loss\n",
    "        # self.initializer = initializer\n",
    "        self.optimizer = optimizer\n",
    "        self.metrics = metrics\n",
    "        self.epochs = epochs\n",
    "        self.batch_size = batch_size\n",
    "        # self.lr = lr\n",
    "        \n",
    "        # Initialize sequential model\n",
    "        self.model = Sequential()\n",
    "        \n",
    "    def model_compile(self):\n",
    "        \n",
    "        # call specific architecture base on kind of LSTM\n",
    "        if self.structure == 'classic':\n",
    "            self.classic_lstm()\n",
    "        if self.structure == 'bidirectional':\n",
    "            self.bidirectional_lstm()\n",
    "    \n",
    "    \n",
    "    def evaluate_model(self, X_train, y_train, X_test, y_test):\n",
    "        \n",
    "        # Fit the model: fixed approach, fit once on the training data and then predict\n",
    "        # each new time step one at a time from the test data.\n",
    "        history_callback = self.model.fit(X_train, y_train,\\\n",
    "        epochs = self.epochs, batch_size = self.batch_size, validation_split=0.1, verbose = 0, shuffle = False)\n",
    "        \n",
    "        # evaluate on test data.\n",
    "        if self.metrics == 'RMSE':\n",
    "            y_pred = self.model.predict(X_test)\n",
    "            metric = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "\n",
    "        return metric, history_callback\n",
    "        \n",
    "            \n",
    "    def classic_lstm(self):\n",
    "\n",
    "        self.model.add(LSTM(self.neurons, activation = self.activation, input_shape=(self.n_steps, self.n_features)))\n",
    "        # self.model.add(Dropout(0.2))\n",
    "        self.model.add(Dense(1))\n",
    "        self.model.compile(loss= self.loss, optimizer = self.optimizer)\n",
    "                       \n",
    "    def bidirectional_lstm(self):\n",
    "        self.model.add(Bidirectional(LSTM(self.neurons, activation = self.activation), input_shape=(self.n_steps, self.n_features)))\n",
    "        # self.model.add(Dropout(0.2))\n",
    "        self.model.add(Dense(1))\n",
    "        self.model.compile(loss= self.loss, optimizer = self.optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "###\n",
    "### DIRECTORIES\n",
    "###\n",
    "\n",
    "PROJECT_DIR = os.getcwd()\n",
    "DATA_DIR = os.path.join(os.path.dirname(PROJECT_DIR),'Data')\n",
    "# SHAPEFILES_DIR = os.path.join(os.path.dirname(PROJECT_DIR),'Shapefiles')\n",
    "RESULTS_DIR = os.path.join(os.path.dirname(PROJECT_DIR),'Results')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "###\n",
    "### LOADING DATA\n",
    "###\n",
    "\n",
    "### 1) Covid_Data: if anything is specified, loads data using url github to repository.\n",
    "###                if a DATA_DIR is specified, loads data downloaded as csv\n",
    "data_provinces, data_regions, data_national = load_data.load_covid_data()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###\n",
    "### MODELS -Logistic Model\n",
    "###\n",
    "\n",
    "today = dt.datetime.now().strftime('%Y-%m-%d')\n",
    "start_date = \"2020-01-01T00:00:00\"\n",
    "FMT = '%Y-%m-%dT%H:%M:%S'\n",
    "data_regions['timestamp'] = data_regions['data'].\\\n",
    "            map(lambda x: (dt.datetime.strptime(x, FMT) - dt.datetime.strptime(\"2020-01-01T00:00:00\", FMT)).days)\n",
    "\n",
    "regions = np.unique(data_regions['denominazione_regione'])\n",
    "\n",
    "# define empty list\n",
    "results = []\n",
    "model = 'Logistic'\n",
    "\n",
    "for region in regions:\n",
    "    \n",
    "    fit = fit_log_model(data_regions, region)\n",
    "    \n",
    "    # erros of estimation\n",
    "    errors = [np.sqrt(fit[1][i][i]) for i in [0,1,2]]\n",
    "    \n",
    "    a = fit[0][0]\n",
    "    b = fit[0][1]\n",
    "    c = fit[0][2] # is the asymptot -> total max of cases!\n",
    "    \n",
    "    # estimate the date of end\n",
    "    sol = int(fsolve(lambda x : logistic_model(x,a,b,c) - int(c),b))\n",
    "    final_date = dt.datetime.strptime(start_date, FMT) + dt.timedelta(days=sol)\n",
    "    final_date = final_date.strftime('%Y-%m-%dT%H:%M:%S')\n",
    "    aux = [region, model, a, b, c, errors[2],final_date]\n",
    "    \n",
    "    results.append(aux)\n",
    "\n",
    "# create dataframe\n",
    "df_logistic_model = pd.DataFrame(results, columns=['Region', 'Model', 'a', 'b', 'c','error to c (+/-)','End_Date'])\n",
    "# df_logistic_model.to_excel(os.path.join(RESULTS_DIR,'Logistic_Forecasting'+'_'+ today + '.xlsx'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Estimated cases\n",
    "'Total estimated cases in Italy: {} with possible error +/- {}'.format(round(np.sum(df_logistic_model['c'])),\\\n",
    "                                                                       round(np.sum(df_logistic_model['error to c (+/-)'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###\n",
    "### PLOT FORECASTING LOGISTIC\n",
    "###\n",
    "\n",
    "plot_forecasting_logistic(data_regions, df_logistic_model, 'Lombardia', FMT, start_date)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0016145279536309816\n"
     ]
    }
   ],
   "source": [
    "###\n",
    "### MODELS - Deep Learning LSTM\n",
    "###\n",
    "\n",
    "region = 'Lombardia'\n",
    "variable = 'totale_casi'\n",
    "\n",
    "aux = data_regions[data_regions['denominazione_regione']==region][variable]\n",
    "# tranform to logarithmic scale\n",
    "aux = np.array(np.log(aux))\n",
    "\n",
    "### DATA PREPARATION\n",
    "\n",
    "# creation of train and test set: small test set since we have little data in this case.\n",
    "train, test = train_test_creation(aux, train_test_split=0.1)\n",
    "\n",
    "# normalization to [-1,1]\n",
    "scaler, train_scaled, test_scaled = scale(train, test)\n",
    "\n",
    "# we have to create data to feed LSTM... \n",
    "n_steps = 2\n",
    "n_features = 1\n",
    "X_train, y_train = create_data(train_scaled, n_steps)\n",
    "X_test, y_test = create_data(test_scaled, n_steps)\n",
    "\n",
    "# ... and then reshape into correct dimension for the network [samples, time_steps, n_features]\n",
    "X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1],1))\n",
    "X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1],1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try some models... \n",
    "model_configuration = get_default_configuration(structure = 'bidirectional',\n",
    "                        n_steps = n_steps, \n",
    "                        n_features = n_features,\n",
    "                        neurons = 64, \n",
    "                        activation = 'relu',\n",
    "                        loss = 'mse',\n",
    "                        optimizer = 'adam',\n",
    "                        metrics = 'RMSE',\n",
    "                        epochs = 100,\n",
    "                        batch_size = 1)\n",
    "\n",
    "prova = univariate_LSTM(structure = model_configuration['structure'],\n",
    "                        n_steps = model_configuration['n_steps'], \n",
    "                        n_features = model_configuration['n_features'],\n",
    "                        neurons = model_configuration['neurons'], \n",
    "                        activation = model_configuration['activation'],\n",
    "                        loss = model_configuration['loss'],\n",
    "                        optimizer = model_configuration['optimizer'],\n",
    "                        metrics = model_configuration['metrics'],\n",
    "                        epochs = model_configuration['epochs'],\n",
    "                        batch_size = model_configuration['batch_size'])\n",
    "\n",
    "prova.model_compile()\n",
    "metric, history = prova.evaluate_model(X_train, y_train, X_test, y_test)\n",
    "print(metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "###\n",
    "### FINE TUNING\n",
    "###\n",
    "\n",
    "region = 'Lombardia'\n",
    "variable = 'totale_casi'\n",
    "\n",
    "aux = data_regions[data_regions['denominazione_regione']==region][variable]\n",
    "# tranform to logarithmic scale\n",
    "aux = np.array(np.log(aux))\n",
    "\n",
    "# define the model\n",
    "n_steps = 1\n",
    "n_features = 1\n",
    "default_configuration = get_default_configuration(structure = 'classic',\n",
    "                        n_steps = n_steps, \n",
    "                        n_features = n_features,\n",
    "                        neurons = 50, \n",
    "                        activation = 'relu',\n",
    "                        loss = 'mse',\n",
    "                        optimizer = 'adam',\n",
    "                        metrics = 'RMSE',\n",
    "                        epochs = 50,\n",
    "                        batch_size = 1)\n",
    "\n",
    "\n",
    "# 1) Fine tuning each single parameters\n",
    "# dictionary for fine tuning\n",
    "# fine_tuning = {\n",
    "# 'structure': ['classic','bidirectional'],\n",
    "# 'n_steps' : [1, 2, 3],\n",
    "# 'epochs' : [5, 20, 50, 100, 400],\n",
    "# 'neurons' : [1, 2, 3, 5, 10],\n",
    "# 'activation': ['linear','relu']}\n",
    "\n",
    "# creation of train and test set\n",
    "# train, test = train_test_creation(aux, train_test_split=0.2)\n",
    "# aaa = run(train, test, model_configuration, tuning_options = fine_tuning)\n",
    "\n",
    "# 2) Fine tuning over various configuration: which suits better for the problem?\n",
    "options = {\n",
    "    \"structure\" : ['classic','bidirectional'],\n",
    "    \"n_steps\" : [1, 2, 3],\n",
    "    \"neurons\": [2, 4, 8, 16, 32, 64],\n",
    "    \"epochs\": [10, 50, 100],\n",
    "    \"activation\": ['linear','relu']\n",
    "}\n",
    "tuning_model = get_tuning_model(options)\n",
    "\n",
    "# creation of train and test set\n",
    "train, test = train_test_creation(aux, train_test_split=0.1)\n",
    "df_results = run(train, test, default_configuration, tuning_options = None, tuning_model=tuning_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>structure</th>\n",
       "      <th>n_steps</th>\n",
       "      <th>neurons</th>\n",
       "      <th>epochs</th>\n",
       "      <th>activation</th>\n",
       "      <th>metric</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>bidirectional</td>\n",
       "      <td>2</td>\n",
       "      <td>64</td>\n",
       "      <td>100</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.000963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>bidirectional</td>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "      <td>50</td>\n",
       "      <td>linear</td>\n",
       "      <td>0.001001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>classic</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>100</td>\n",
       "      <td>linear</td>\n",
       "      <td>0.001019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>bidirectional</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>50</td>\n",
       "      <td>linear</td>\n",
       "      <td>0.001035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>classic</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>100</td>\n",
       "      <td>linear</td>\n",
       "      <td>0.001056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>bidirectional</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.920221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>classic</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.925219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>bidirectional</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.925598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>classic</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>linear</td>\n",
       "      <td>0.953734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>classic</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.956433</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>216 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         structure  n_steps  neurons  epochs activation    metric\n",
       "179  bidirectional        2       64     100       relu  0.000963\n",
       "164  bidirectional        2       16      50     linear  0.001001\n",
       "52         classic        2        8     100     linear  0.001019\n",
       "158  bidirectional        2        8      50     linear  0.001035\n",
       "22         classic        1       16     100     linear  0.001056\n",
       "..             ...      ...      ...     ...        ...       ...\n",
       "145  bidirectional        2        2      10       relu  0.920221\n",
       "37         classic        2        2      10       relu  0.925219\n",
       "151  bidirectional        2        4      10       relu  0.925598\n",
       "0          classic        1        2      10     linear  0.953734\n",
       "43         classic        2        4      10       relu  0.956433\n",
       "\n",
       "[216 rows x 6 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results.sort_values('metric')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimal model from fine tuning.. \n",
    "model_configuration = get_default_configuration(structure = 'bidirectional',\n",
    "                        n_steps = n_steps, \n",
    "                        n_features = n_features,\n",
    "                        neurons = 64, \n",
    "                        activation = 'relu',\n",
    "                        loss = 'mse',\n",
    "                        optimizer = 'adam',\n",
    "                        metrics = 'RMSE',\n",
    "                        epochs = 100,\n",
    "                        batch_size = 1)\n",
    "\n",
    "prova = univariate_LSTM(structure = model_configuration['structure'],\n",
    "                        n_steps = model_configuration['n_steps'], \n",
    "                        n_features = model_configuration['n_features'],\n",
    "                        neurons = model_configuration['neurons'], \n",
    "                        activation = model_configuration['activation'],\n",
    "                        loss = model_configuration['loss'],\n",
    "                        optimizer = model_configuration['optimizer'],\n",
    "                        metrics = model_configuration['metrics'],\n",
    "                        epochs = model_configuration['epochs'],\n",
    "                        batch_size = model_configuration['batch_size'])\n",
    "\n",
    "prova.model_compile()\n",
    "metric, history = prova.evaluate_model(X_train, y_train, X_test, y_test)\n",
    "print(metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "###\n",
    "### PLOT METRICS\n",
    "###\n",
    "\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction=1, Predicted=48813.308594, Expected=49118.000000\n",
      "Prediction=2, Predicted=50224.718750, Expected=50455.000000\n",
      "Prediction=3, Predicted=51580.980469, Expected=51534.000000\n"
     ]
    }
   ],
   "source": [
    "###\n",
    "### FORECASTING\n",
    "###\n",
    "\n",
    "# test data\n",
    "predictions = list()\n",
    "\n",
    "for i in range(X_test.shape[0]):\n",
    "    # make one-step forecast\n",
    "    X, y = X_test[i,:], y_test[i]\n",
    "    yhat = forecast_univariate_lstm(prova.model, X)\n",
    "    yhat = invert_scale(scaler, yhat)\n",
    "    y_test_inversed = invert_scale(scaler, y_test[i]) \n",
    "    # store forecast\n",
    "    predictions.append(yhat)\n",
    "    print('Prediction=%d, Predicted=%f, Expected=%f' % (i+1, np.exp(yhat), np.exp(y_test_inversed)))\n",
    "\n",
    "# predictions\n",
    "predictions_new = list()\n",
    "window = 50\n",
    "predictions_new = forecast_point_by_point_univariate_lstm(test_scaled,n_steps,forecast_window = window)\n",
    "# convert back to reversed scale\n",
    "for i in range(len(predictions_new)):\n",
    "    predictions_new[i] = invert_scale(scaler, predictions_new[i])[0,0]\n",
    "    \n",
    "predictions_new = np.array(np.exp(predictions_new))\n",
    "predictions_new = predictions_new.astype('int')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lombardia\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "###\n",
    "### PLOT FORECAST\n",
    "###\n",
    "\n",
    "plot_forecasting_LSTM(data_regions, 'Lombardia', 'totale_casi', predictions_new)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GEOPANDAS",
   "language": "python",
   "name": "geopandas"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
